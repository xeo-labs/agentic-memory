"""
Base classes and utilities for LLM backends.

Provides the abstract interface that all LLM backends must implement,
shared data structures for messages and responses, and common utility
functions such as embedding normalization.
"""

from __future__ import annotations

import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# Exceptions
# ---------------------------------------------------------------------------

class LLMError(Exception):
    """Raised when an LLM backend encounters an unrecoverable error.

    Examples include missing API keys, unreachable services, rate-limit
    exhaustion, and malformed responses.
    """


# ---------------------------------------------------------------------------
# Data classes
# ---------------------------------------------------------------------------

@dataclass(frozen=True, slots=True)
class Message:
    """A single message in a conversation.

    Attributes:
        role: The role of the message author.  Typical values are
            ``"system"``, ``"user"``, and ``"assistant"``.
        content: The textual content of the message.
    """

    role: str
    content: str


@dataclass(frozen=True, slots=True)
class LLMResponse:
    """The result returned by an LLM chat completion call.

    Attributes:
        content: The text generated by the model.
        model: The model identifier that produced the response.
        input_tokens: Number of tokens in the prompt.
        output_tokens: Number of tokens in the completion.
    """

    content: str
    model: str
    input_tokens: int
    output_tokens: int


# ---------------------------------------------------------------------------
# Abstract base class
# ---------------------------------------------------------------------------

class LLMBackend(ABC):
    """Abstract interface for language-model backends.

    Every concrete backend (Anthropic, OpenAI, Ollama, ...) must subclass
    this and implement all four abstract methods.
    """

    @abstractmethod
    def chat(self, messages: list[Message]) -> LLMResponse:
        """Send a list of messages and return a model completion.

        Args:
            messages: Ordered conversation history.

        Returns:
            An :class:`LLMResponse` with the generated text and token counts.

        Raises:
            LLMError: On any API or network failure.
        """

    @abstractmethod
    def chat_json(self, messages: list[Message]) -> dict:
        """Like :meth:`chat`, but parse the response as JSON.

        The backend is responsible for instructing the model to return valid
        JSON (via system prompts, response-format parameters, or both) and
        for parsing the result.

        Args:
            messages: Ordered conversation history.

        Returns:
            The parsed JSON object as a Python ``dict``.

        Raises:
            LLMError: On API failure or if the model output is not valid JSON
                after retries.
        """

    @abstractmethod
    def embed(self, text: str) -> list[float]:
        """Return a fixed-dimension embedding vector for *text*.

        The vector length should be normalized to ``128`` dimensions by
        truncating or zero-padding as needed (see
        :func:`normalize_embedding`).

        Args:
            text: The input string to embed.

        Returns:
            A list of 128 floats representing the embedding.

        Raises:
            LLMError: On API or network failure.
        """

    @abstractmethod
    def name(self) -> str:
        """Return a human-readable identifier for this backend.

        Example return values: ``"Anthropic (claude-sonnet-4-20250514)"``,
        ``"OpenAI (gpt-4o)"``.
        """


# ---------------------------------------------------------------------------
# Utilities
# ---------------------------------------------------------------------------

def normalize_embedding(vec: list[float], target_dim: int = 128) -> list[float]:
    """Truncate or zero-pad *vec* so it has exactly *target_dim* elements.

    This allows different embedding models (which produce vectors of varying
    dimensionality) to be stored and compared in a uniform way.

    Args:
        vec: The raw embedding vector.
        target_dim: Desired output length.  Defaults to ``128``.

    Returns:
        A list of exactly *target_dim* floats.
    """
    if len(vec) >= target_dim:
        return vec[:target_dim]
    # Pad with zeros to reach target_dim
    return vec + [0.0] * (target_dim - len(vec))


def sanitize_json_text(text: str) -> str:
    """Clean raw LLM output so it can be parsed as JSON.

    Many smaller or less-capable LLMs wrap valid JSON in markdown code fences,
    prepend/append prose, or include control characters.  This function strips
    those artefacts **without altering** the JSON payload itself.

    The sanitisation pipeline:

    1. Strip leading/trailing whitespace.
    2. Remove markdown code fences (`` ```json ... ``` `` or `` ``` ... ``` ``).
    3. If the result still isn't a bare ``{...}`` or ``[...]``, attempt to
       locate the first ``{`` and last ``}`` (or ``[`` and ``]``) and extract
       that substring.
    4. Strip any remaining Unicode BOM or zero-width characters.

    Args:
        text: Raw model output that is *expected* to be JSON.

    Returns:
        A cleaned string that is more likely to ``json.loads()`` successfully.
        If the input is empty or ``None``, returns ``"{}"``.
    """
    import re

    if not text:
        return "{}"

    # Step 1: basic trim
    cleaned = text.strip()

    # Step 2: strip markdown code fences
    # Handles ```json\n...\n```, ```\n...\n```, and variants with trailing text
    fence_pattern = re.compile(
        r"^```(?:json|JSON)?\s*\n?(.*?)```\s*$",
        re.DOTALL,
    )
    match = fence_pattern.match(cleaned)
    if match:
        cleaned = match.group(1).strip()

    # Also handle cases where fences appear mid-text (e.g. "Here is the JSON:\n```json\n{...}\n```")
    if "```" in cleaned:
        inner_match = re.search(
            r"```(?:json|JSON)?\s*\n?(.*?)```",
            cleaned,
            re.DOTALL,
        )
        if inner_match:
            cleaned = inner_match.group(1).strip()

    # Step 3: if it doesn't start with { or [, find the first { or [
    cleaned = cleaned.strip()
    if cleaned and cleaned[0] not in ("{", "["):
        # Try to find the JSON object or array
        brace_start = cleaned.find("{")
        bracket_start = cleaned.find("[")
        if brace_start >= 0 and (bracket_start < 0 or brace_start <= bracket_start):
            # Extract from first { to last }
            brace_end = cleaned.rfind("}")
            if brace_end > brace_start:
                cleaned = cleaned[brace_start : brace_end + 1]
        elif bracket_start >= 0:
            bracket_end = cleaned.rfind("]")
            if bracket_end > bracket_start:
                cleaned = cleaned[bracket_start : bracket_end + 1]

    # Step 4: remove Unicode BOM and zero-width chars
    cleaned = cleaned.lstrip("\ufeff").replace("\u200b", "").replace("\u200c", "")

    return cleaned if cleaned else "{}"
